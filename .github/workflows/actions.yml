name: Run get_stock_data Python script

on:
  schedule:
    - cron: '30 21 * * *'  # Runs daily at 9:30 PM UTC, which is 11:30 PM UTC+2
  workflow_dispatch:  # Optional: allows manual trigger from GitHub UI

jobs:
  combine_csvs:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt  # Ensure you have a requirements.txt file

      - name: Decode and Save Google Cloud Credentials
        run: |
          echo "${{ secrets.GOOGLE_CREDENTIALS_JSON }}" | base64 --decode > $HOME/google-credentials.json

      - name: Authenticate with Google Cloud
        run: gcloud auth activate-service-account --key-file=$HOME/google-credentials.json

      - name: Set environment variable for Python
        run: echo "GOOGLE_CREDENTIALS_JSON=$HOME/google-credentials.json" >> $GITHUB_ENV

      - name: Set environment variable for API_KEY
        run: echo "API_KEY=${{ secrets.API_KEY }}" >> $GITHUB_ENV

      - name: Check if combine_csvs has run before
        id: check_marker
        run: |
          if [ -f combine_csvs_run_marker.txt ]; then
            echo "Marker file exists, skipping combine_csvs.py"
            echo "has_run=true" >> $GITHUB_ENV
          else
            echo "Marker file does not exist, will run combine_csvs.py"
            echo "has_run=false" >> $GITHUB_ENV
          fi

      - name: Run combine_csvs script (only once)
        if: env.has_run == 'false'
        run: |
          echo "Running combine_csvs.py for the first time..."
          python combine_csvs.py  # Run the combine CSV script
          touch combine_csvs_run_marker.txt  # Create the marker file
          echo "Marker file created at: $(pwd)/combine_csvs_run_marker.txt"  # Debugging line
          ls -la $(pwd)/combine_csvs_run_marker.txt  # List file details for verification

      - name: Verify marker file creation
        if: env.has_run == 'false'
        run: ls -la combine_csvs_run_marker.txt  # List details of the marker file for verification

      - name: Upload marker file as artifact
        if: env.has_run == 'false'
        uses: actions/upload-artifact@v4
        with:
          name: combine_csvs_marker
          path: combine_csvs_run_marker.txt  # Ensure you're uploading the file directly, not as a zip

  update_database:
    runs-on: ubuntu-latest
    needs: combine_csvs  # This ensures that `update_database` runs only after `combine_csvs` finishes

    steps:
      - name: Download marker file artifact
        uses: actions/download-artifact@v4
        with:
          name: combine_csvs_marker

      - name: Verify marker file download
        run: |
          if [ -f combine_csvs_marker/combine_csvs_run_marker.txt ]; then
            echo "Text marker file exists, proceeding with the database update"
          elif [ -f combine_csvs_marker/combine_csvs_marker.zip ]; then
            echo "ZIP marker file exists, proceeding with extraction"
            # If ZIP file exists, you can extract it here
            unzip combine_csvs_marker/combine_csvs_marker.zip -d combine_csvs_marker
          else
            echo "No valid marker file found, skipping database update"
            exit 1  # You can change this to skip the job or handle differently
          fi

      - name: Move marker file to the correct location
        run: |
          # Move the text file if it exists
          if [ -f combine_csvs_marker/combine_csvs_run_marker.txt ]; then
            mv combine_csvs_marker/combine_csvs_run_marker.txt $HOME/combine_csvs_run_marker.txt
          # If ZIP file was extracted, move the extracted text file
          elif [ -f combine_csvs_marker/combine_csvs_run_marker.zip ]; then
            mv combine_csvs_marker/combine_csvs_run_marker.zip $HOME/combine_csvs_run_marker.zip
          fi

      - name: Run update_database script
        run: python update_database.py
